{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79de1fa9",
   "metadata": {},
   "source": [
    "## OR 데이터 인식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0ea298",
   "metadata": {},
   "source": [
    "# 사이킷 런의 디자인 패턴\n",
    "\n",
    "- 데이터 읽기\n",
    "- 모델 객체 생성\n",
    "- 모델 학습\n",
    "- 예측\n",
    "- 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4384bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2094d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련 집합 구축\n",
    "x=[[0,0],[0,1],[1,0],[1,1]]\n",
    "y=[-1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d75754b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit 함수로 perceptron 학습\n",
    "p=Perceptron()    #perceptron 함수 호출하여 객체 p에 저장\n",
    "p.fit(x,y)        #fit 함수로 x와 y에 대한 학습을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfaacbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습된 퍼셉트론의 매개변수:  [[2. 2.]] [-1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"학습된 퍼셉트론의 매개변수: \",p.coef_,p.intercept_)  #학습을 마친 퍼셉트론의 매개변수, 즉 가중치 w0,w1,w2를 출력한다.\n",
    "#coef_: w1,w2 , intercept_ : w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11d8f0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련집합에 대한 예측:  [-1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련집합에 대한 예측: \",p.predict(x)) #predict 함수를 사용해 훈련집합x를 테스트용으로 간주하고 예측을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec3e16e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확률 측정:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"정확률 측정: \",p.score(x,y)*100,\"%\") #score 함수는 x를 퍼셉트론으로 예측한 값과 y(레이블)을 비교하여 맞힌 샘플 개수를 세어 정확률을 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d47193e",
   "metadata": {},
   "source": [
    "## 필기 숫자 데이터 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ad0c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "190a87e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터셋을 읽고 훈련집합과 테스트집합으로 분할\n",
    "digit=datasets.load_digits()\n",
    "x_train,x_test,y_train,y_test=train_test_split(digit.data,digit.target,train_size=0.6) #train_test_split 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75910779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(eta0=0.001, max_iter=100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit 함수로 Perceptron 학습\n",
    "p=Perceptron(max_iter=100,eta0=0.001,verbose=0) #모델 객체 생성 :sklearn의 perceptron 함수\n",
    "p.fit(x_train,y_train) #digit 데이터로 모델링 -> 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0172434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=p.predict(x_test) #테스트 집합으로 예측 > 학습된 모델로 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea4ac89",
   "metadata": {},
   "source": [
    "### 성능 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e431d752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. 61.  0.  0.  1.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0. 75.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. 63.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. 71.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  4.  0. 79.  0.  0.  0.  2.]\n",
      " [ 0.  1.  0.  0.  1.  0. 65.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0. 62.  1.  0.]\n",
      " [ 0. 14.  2.  4.  2.  1.  1.  1. 70.  5.]\n",
      " [ 0.  1.  0.  1.  1.  0.  0.  1.  0. 58.]]\n"
     ]
    }
   ],
   "source": [
    "#혼동 행렬\n",
    "conf=np.zeros((10,10))\n",
    "for i in range(len(res)):\n",
    "    conf[res[i]][y_test[i]]+=1\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29ca4027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.18497913769124 %\n"
     ]
    }
   ],
   "source": [
    "#정확률 계산\n",
    "no_correct=0\n",
    "for i in range(10):\n",
    "    no_correct+=conf[i][i]\n",
    "accuracy=no_correct/len(res)\n",
    "print(accuracy*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe89833",
   "metadata": {},
   "source": [
    "# 다층 퍼셉트론 프로그래밍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1f6f2e",
   "metadata": {},
   "source": [
    "## sklearn의 필기 숫자 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee01e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8937c7d0",
   "metadata": {},
   "source": [
    "##### 데이터 셋을 읽고 훈련 집합과 테스트 집합으로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a60fef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "digit=datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeb5a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(digit.data,digit.target,train_size=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cb2137",
   "metadata": {},
   "source": [
    "##### MLP 분류기 모델을 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e5d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp=MLPClassifier(hidden_layer_sizes=(100),learning_rate_init=0.001,batch_size=32,max_iter=300,solver='sgd',verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad922cbb",
   "metadata": {},
   "source": [
    "##### 하이퍼 매개변수 살피기\n",
    "- hidden layer size : 노드가 100개인 은닉층 하나를 둬라\n",
    "  > (100,80) : 노드가 100개인 은닉층과 노드가 80개인 은닉층을 두어 은닉층이 2개인 다층 퍼셉트론\n",
    "- 나머지 : 학습률을 0.001, 미니 배치 크기를 32, 최대 세대수를 300으로 설정하여 **스토케스틱 경사 하강법** 사용하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f1daae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.71552641\n",
      "Iteration 2, loss = 0.28271789\n",
      "Iteration 3, loss = 0.19721607\n",
      "Iteration 4, loss = 0.14870148\n",
      "Iteration 5, loss = 0.12195080\n",
      "Iteration 6, loss = 0.10326788\n",
      "Iteration 7, loss = 0.08917248\n",
      "Iteration 8, loss = 0.07782328\n",
      "Iteration 9, loss = 0.06707542\n",
      "Iteration 10, loss = 0.06306242\n",
      "Iteration 11, loss = 0.05571084\n",
      "Iteration 12, loss = 0.05047992\n",
      "Iteration 13, loss = 0.04746593\n",
      "Iteration 14, loss = 0.04202160\n",
      "Iteration 15, loss = 0.04102589\n",
      "Iteration 16, loss = 0.03661391\n",
      "Iteration 17, loss = 0.03613750\n",
      "Iteration 18, loss = 0.03075455\n",
      "Iteration 19, loss = 0.02901092\n",
      "Iteration 20, loss = 0.02766658\n",
      "Iteration 21, loss = 0.02703221\n",
      "Iteration 22, loss = 0.02490051\n",
      "Iteration 23, loss = 0.02379030\n",
      "Iteration 24, loss = 0.02268045\n",
      "Iteration 25, loss = 0.02271619\n",
      "Iteration 26, loss = 0.02156309\n",
      "Iteration 27, loss = 0.01950871\n",
      "Iteration 28, loss = 0.01895399\n",
      "Iteration 29, loss = 0.01867952\n",
      "Iteration 30, loss = 0.01753876\n",
      "Iteration 31, loss = 0.01716896\n",
      "Iteration 32, loss = 0.01603006\n",
      "Iteration 33, loss = 0.01631468\n",
      "Iteration 34, loss = 0.01611022\n",
      "Iteration 35, loss = 0.01535145\n",
      "Iteration 36, loss = 0.01537091\n",
      "Iteration 37, loss = 0.01413364\n",
      "Iteration 38, loss = 0.01383360\n",
      "Iteration 39, loss = 0.01316496\n",
      "Iteration 40, loss = 0.01301589\n",
      "Iteration 41, loss = 0.01239428\n",
      "Iteration 42, loss = 0.01255205\n",
      "Iteration 43, loss = 0.01184341\n",
      "Iteration 44, loss = 0.01140797\n",
      "Iteration 45, loss = 0.01122671\n",
      "Iteration 46, loss = 0.01103631\n",
      "Iteration 47, loss = 0.01070195\n",
      "Iteration 48, loss = 0.01065588\n",
      "Iteration 49, loss = 0.01039962\n",
      "Iteration 50, loss = 0.01047591\n",
      "Iteration 51, loss = 0.00989914\n",
      "Iteration 52, loss = 0.00961454\n",
      "Iteration 53, loss = 0.00941336\n",
      "Iteration 54, loss = 0.00936789\n",
      "Iteration 55, loss = 0.00923552\n",
      "Iteration 56, loss = 0.00897404\n",
      "Iteration 57, loss = 0.00873040\n",
      "Iteration 58, loss = 0.00873757\n",
      "Iteration 59, loss = 0.00851121\n",
      "Iteration 60, loss = 0.00828488\n",
      "Iteration 61, loss = 0.00833920\n",
      "Iteration 62, loss = 0.00808192\n",
      "Iteration 63, loss = 0.00788326\n",
      "Iteration 64, loss = 0.00785815\n",
      "Iteration 65, loss = 0.00765179\n",
      "Iteration 66, loss = 0.00752340\n",
      "Iteration 67, loss = 0.00731268\n",
      "Iteration 68, loss = 0.00729419\n",
      "Iteration 69, loss = 0.00715302\n",
      "Iteration 70, loss = 0.00707124\n",
      "Iteration 71, loss = 0.00699246\n",
      "Iteration 72, loss = 0.00685531\n",
      "Iteration 73, loss = 0.00672913\n",
      "Iteration 74, loss = 0.00669219\n",
      "Iteration 75, loss = 0.00661851\n",
      "Iteration 76, loss = 0.00659864\n",
      "Iteration 77, loss = 0.00638115\n",
      "Iteration 78, loss = 0.00629898\n",
      "Iteration 79, loss = 0.00618305\n",
      "Iteration 80, loss = 0.00618166\n",
      "Iteration 81, loss = 0.00601727\n",
      "Iteration 82, loss = 0.00603843\n",
      "Iteration 83, loss = 0.00589846\n",
      "Iteration 84, loss = 0.00580343\n",
      "Iteration 85, loss = 0.00574570\n",
      "Iteration 86, loss = 0.00569405\n",
      "Iteration 87, loss = 0.00564062\n",
      "Iteration 88, loss = 0.00555527\n",
      "Iteration 89, loss = 0.00553629\n",
      "Iteration 90, loss = 0.00542837\n",
      "Iteration 91, loss = 0.00536796\n",
      "Iteration 92, loss = 0.00531790\n",
      "Iteration 93, loss = 0.00525118\n",
      "Iteration 94, loss = 0.00515163\n",
      "Iteration 95, loss = 0.00514802\n",
      "Iteration 96, loss = 0.00507965\n",
      "Iteration 97, loss = 0.00506305\n",
      "Iteration 98, loss = 0.00496381\n",
      "Iteration 99, loss = 0.00489851\n",
      "Iteration 100, loss = 0.00489587\n",
      "Iteration 101, loss = 0.00485582\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(batch_size=32, hidden_layer_sizes=100, max_iter=300, solver='sgd',\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b888c8fc",
   "metadata": {},
   "source": [
    "##### 테스트 집합으로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dae70333",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=mlp.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cbb48d",
   "metadata": {},
   "source": [
    "##### 혼동행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7e77acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=np.zeros((10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "999230d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68.  0.  0.  0.  0.  1.  1.  0.  1.  0.]\n",
      " [ 0. 71.  2.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0. 75.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. 71.  0.  0.  0.  1.  0.  1.]\n",
      " [ 1.  1.  0.  0. 78.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0. 60.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1. 59.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0. 72.  0.  0.]\n",
      " [ 0.  2.  1.  1.  1.  0.  1.  0. 62.  0.]\n",
      " [ 0.  0.  0.  0.  0.  3.  0.  1.  1. 77.]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(res)):\n",
    "    conf[res[i]][y_test[i]]+=1\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8606f9",
   "metadata": {},
   "source": [
    "##### 정확률 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9420fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 집합에 대한 정확률은  96.38386648122392 %입니다.\n"
     ]
    }
   ],
   "source": [
    "no_correct=0\n",
    "for i in range(10):\n",
    "    no_correct+=conf[i][i]\n",
    "accuracy=no_correct/len(res)\n",
    "print(\"테스트 집합에 대한 정확률은 \", accuracy*100,\"%입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad581a",
   "metadata": {},
   "source": [
    "## MNIST 데이터셋을 다층 퍼셉트론으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1e9c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ca9699",
   "metadata": {},
   "source": [
    "##### 데이터 셋을 읽고 훈련/테스트 데이터로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afb82b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=fetch_openml('mnist_784')\n",
    "mnist.data=mnist.data/255.0\n",
    "x_train=mnist.data[:60000]; x_test=mnist.data[60000:]\n",
    "y_train=np.int16(mnist.target[:60000]); y_test=np.int16(mnist.target[60000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d81719e",
   "metadata": {},
   "source": [
    "##### MLP 분류기 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d2e60b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp=MLPClassifier(hidden_layer_sizes=(100),learning_rate_init=0.001,batch_size=512,max_iter=300,solver='adam',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42c45650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.61456712\n",
      "Iteration 2, loss = 0.26291586\n",
      "Iteration 3, loss = 0.21087402\n",
      "Iteration 4, loss = 0.17928135\n",
      "Iteration 5, loss = 0.15531062\n",
      "Iteration 6, loss = 0.13650675\n",
      "Iteration 7, loss = 0.12098139\n",
      "Iteration 8, loss = 0.10847372\n",
      "Iteration 9, loss = 0.09848476\n",
      "Iteration 10, loss = 0.08964481\n",
      "Iteration 11, loss = 0.08219066\n",
      "Iteration 12, loss = 0.07550918\n",
      "Iteration 13, loss = 0.06911999\n",
      "Iteration 14, loss = 0.06360781\n",
      "Iteration 15, loss = 0.05905341\n",
      "Iteration 16, loss = 0.05464478\n",
      "Iteration 17, loss = 0.05058346\n",
      "Iteration 18, loss = 0.04678050\n",
      "Iteration 19, loss = 0.04333599\n",
      "Iteration 20, loss = 0.04070796\n",
      "Iteration 21, loss = 0.03792621\n",
      "Iteration 22, loss = 0.03499545\n",
      "Iteration 23, loss = 0.03292134\n",
      "Iteration 24, loss = 0.03050904\n",
      "Iteration 25, loss = 0.02794301\n",
      "Iteration 26, loss = 0.02661371\n",
      "Iteration 27, loss = 0.02420656\n",
      "Iteration 28, loss = 0.02317294\n",
      "Iteration 29, loss = 0.02163818\n",
      "Iteration 30, loss = 0.01968901\n",
      "Iteration 31, loss = 0.01823704\n",
      "Iteration 32, loss = 0.01703718\n",
      "Iteration 33, loss = 0.01593695\n",
      "Iteration 34, loss = 0.01485206\n",
      "Iteration 35, loss = 0.01392244\n",
      "Iteration 36, loss = 0.01304260\n",
      "Iteration 37, loss = 0.01184488\n",
      "Iteration 38, loss = 0.01111936\n",
      "Iteration 39, loss = 0.01052634\n",
      "Iteration 40, loss = 0.00968436\n",
      "Iteration 41, loss = 0.00914977\n",
      "Iteration 42, loss = 0.00872965\n",
      "Iteration 43, loss = 0.00803966\n",
      "Iteration 44, loss = 0.00736151\n",
      "Iteration 45, loss = 0.00690043\n",
      "Iteration 46, loss = 0.00649506\n",
      "Iteration 47, loss = 0.00595057\n",
      "Iteration 48, loss = 0.00562444\n",
      "Iteration 49, loss = 0.00521780\n",
      "Iteration 50, loss = 0.00496506\n",
      "Iteration 51, loss = 0.00466883\n",
      "Iteration 52, loss = 0.00417453\n",
      "Iteration 53, loss = 0.00436962\n",
      "Iteration 54, loss = 0.00377232\n",
      "Iteration 55, loss = 0.00337484\n",
      "Iteration 56, loss = 0.00350767\n",
      "Iteration 57, loss = 0.00304041\n",
      "Iteration 58, loss = 0.00286134\n",
      "Iteration 59, loss = 0.00267662\n",
      "Iteration 60, loss = 0.00245809\n",
      "Iteration 61, loss = 0.00241179\n",
      "Iteration 62, loss = 0.00220213\n",
      "Iteration 63, loss = 0.00216725\n",
      "Iteration 64, loss = 0.00198416\n",
      "Iteration 65, loss = 0.00189103\n",
      "Iteration 66, loss = 0.00189839\n",
      "Iteration 67, loss = 0.00172306\n",
      "Iteration 68, loss = 0.00159818\n",
      "Iteration 69, loss = 0.00149045\n",
      "Iteration 70, loss = 0.00145739\n",
      "Iteration 71, loss = 0.00142536\n",
      "Iteration 72, loss = 0.00134330\n",
      "Iteration 73, loss = 0.00138687\n",
      "Iteration 74, loss = 0.00121088\n",
      "Iteration 75, loss = 0.00110623\n",
      "Iteration 76, loss = 0.00106673\n",
      "Iteration 77, loss = 0.00135962\n",
      "Iteration 78, loss = 0.00098948\n",
      "Iteration 79, loss = 0.00090822\n",
      "Iteration 80, loss = 0.00094267\n",
      "Iteration 81, loss = 0.00100767\n",
      "Iteration 82, loss = 0.00088604\n",
      "Iteration 83, loss = 0.00079919\n",
      "Iteration 84, loss = 0.00075165\n",
      "Iteration 85, loss = 0.00074238\n",
      "Iteration 86, loss = 0.00069926\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(batch_size=512, hidden_layer_sizes=100, max_iter=300,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015de401",
   "metadata": {},
   "source": [
    "##### 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "998a3fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=mlp.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471e2f5c",
   "metadata": {},
   "source": [
    "##### 혼동 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adb1512f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 971    0    4    0    1    3    4    1    4    2]\n",
      " [   0 1126    3    0    1    0    2    3    1    2]\n",
      " [   1    3 1005    6    5    0    2   12    3    0]\n",
      " [   0    1    6  988    1   10    1    7    8    5]\n",
      " [   1    0    0    1  963    2    2    1    3    8]\n",
      " [   2    1    0    3    0  867    7    0    4    4]\n",
      " [   2    1    2    0    2    5  937    0    1    0]\n",
      " [   1    1    5    4    2    1    1  996    3    2]\n",
      " [   2    2    7    3    1    3    2    3  943    2]\n",
      " [   0    0    0    5    6    1    0    5    4  984]]\n"
     ]
    }
   ],
   "source": [
    "conf=np.zeros((10,10),dtype=np.int16)\n",
    "for i in range(len(res)):\n",
    "    conf[res[i]][y_test[i]]+=1\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f38d00",
   "metadata": {},
   "source": [
    "##### 정확률 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb69a3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확률은 97.8 %입니다.\n"
     ]
    }
   ],
   "source": [
    "no_correct=0\n",
    "for i in range(10):\n",
    "    no_correct+=conf[i][i]\n",
    "accuracy=no_correct/len(res)\n",
    "print(\"정확률은\",accuracy*100,\"%입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb91a61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
